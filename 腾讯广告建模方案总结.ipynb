{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random\n",
    "import pandas as pd \n",
    "import scipy.special as special \n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from scipy import stats \n",
    "from collections import OrderedDict, namedtuple \n",
    "from itertools import chain \n",
    "from tensorflow.python.keras.initializers import RandomNormal \n",
    "from tensorflow.python.keras.layers import * \n",
    "from tensorflow.python.keras.regularizers import  l2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianSmoothing(object):\n",
    "    def __init__(self, alpha, beta):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def sample(self, alpha, beta, num, imp_upperbound):\n",
    "        sample = np.random.beta(alpha, beta, num)\n",
    "        I = []\n",
    "        C = []\n",
    "        for clk_rt in sample:\n",
    "            imp = random.random() * imp_upperbound\n",
    "            clk = imp * clk_rt\n",
    "            I.append(int(imp))\n",
    "            C.append(int(clk))\n",
    "        return I, C\n",
    "\n",
    "    def update(self, imps, clks, iter_num, epsilon):\n",
    "        for i in range(iter_num):\n",
    "            new_alpha, new_beta = self.__fixed_point_iteration(imps, clks, self.alpha, self.beta)\n",
    "            if abs(new_alpha-self.alpha)<epsilon and abs(new_beta-self.beta)<epsilon:\n",
    "                break\n",
    "            self.alpha = new_alpha\n",
    "            self.beta = new_beta\n",
    "\n",
    "    def __fixed_point_iteration(self, imps, clks, alpha, beta):\n",
    "        numerator_alpha = 0.0\n",
    "        numerator_beta = 0.0\n",
    "        denominator = 0.0\n",
    "\n",
    "        for i in range(len(imps)):\n",
    "            # special.digamma(gamma函数的导数)\n",
    "            numerator_alpha += (special.digamma(clks[i]+alpha) - special.digamma(alpha))\n",
    "            numerator_beta += (special.digamma(imps[i]-clks[i]+beta) - special.digamma(beta))\n",
    "            denominator += (special.digamma(imps[i]+alpha+beta) - special.digamma(alpha+beta))\n",
    "\n",
    "        return alpha*(numerator_alpha/denominator), beta*(numerator_beta/denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"随机变量（beta 分布）->字典特征\"\"\"\n",
    "def beta_ppf(alpha, beta, dim):\n",
    "    return stats.beta(alpha, beta).ppf([x/(dim+1) for x in range(0,dim+2)])\n",
    "    # stats.beta.ppf()   # 累积分布的反函数\n",
    "\n",
    "def beta_prior_feat_2_vec(data, key_col, count_col, sum_col, dim):\n",
    "    data_simple = data.drop_duplicates([key_col],keep='last')\n",
    "    bs = BayesianSmoothing(1, 1)\n",
    "    bs.update(data_simple[count_col].values, data_simple[sum_col].values, 1000, 0.0000000001)\n",
    "    if np.isnan(bs.alpha) or np.isnan(bs.beta):\n",
    "        bs.alpha, bs.beta = 0, 0\n",
    "\n",
    "    data[key_col + '_beta_cdf_value'] = list(\n",
    "        map(lambda x,y:beta_cdf(x,y,dim), data[sum_col]+bs.alpha, data[count_col]-data[sum_col]+bs.beta))\n",
    "    data[key_col + '_beta_ppf_value'] = list(\n",
    "        map(lambda x,y:beta_ppf(x,y,dim), data[sum_col] + bs.alpha, data[count_col] - data[sum_col] + bs.beta))\n",
    "    data[key_col + '_beta_key'] = [np.array([i for i in range(dim)]) for _ in range(data.shape[0])]\n",
    "    \n",
    "    return data[key_col+'_beta_cdf_value'].values, data[key_col + '_beta_ppf_value'].values, data[key_col + '_beta_key'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "浮点数->字典特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4], [3, 5, 7, 9.0]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = [[1,2,3,4],\n",
    "     [3,5,7,9.0]]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.35462628e-04, 9.11881966e-04, 2.47875218e-03, 6.73794700e-03],\n",
       "       [2.47875218e-03, 1.83156389e-02, 1.35335283e-01, 1.00000000e+00]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(tmp - np.max(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0321, 0.0871, 0.2369, 0.6439],\n",
       "        [0.0021, 0.0158, 0.1171, 0.8650]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(torch.tensor(tmp), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64391426, 0.64391426])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.apply_along_axis(lambda x: np.exp(x-np.max(x)), 1, tmp)\n",
    "denominator = np.apply_along_axis(lambda x: 1.0 / np.sum(x), 1, x)\n",
    "denominator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  6,  9, 12])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3,4]).dot(3)  # np.array([1,2,3,4]) * 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_softmax(x):\n",
    "    orig_shape = x.shape\n",
    "    if len(x.shape) > 1:\n",
    "        exp_minmax = lambda x: np.exp(x - np.max(x))   # 减掉最大值，防止溢出\n",
    "        denom = lambda x: 1.0 / np.sum(x)\n",
    "        x = np.apply_along_axis(exp_minmax,1,x)\n",
    "        denominator = np.apply_along_axis(denom,1,x)\n",
    "        if len(denominator.shape) == 1:\n",
    "            denominator = denominator.reshape((denominator.shape[0],1))\n",
    "        x = x * denominator\n",
    "    else:\n",
    "        x_max = np.max(x)\n",
    "        x = x - x_max\n",
    "        numerator = np.exp(x)\n",
    "        denominator =  1.0 / np.sum(numerator)\n",
    "        x = numerator.dot(denominator)\n",
    "    assert x.shape == orig_shape\n",
    "    return x\n",
    "\n",
    "def float2vec(float_feat, bar_num = 20, method = 'gravitation'):\n",
    "    float_feat = (float_feat-np.min(float_feat))*1.0 / np.max(float_feat-np.min(float_feat))   # (x-min)/max((x-min))\n",
    "    key_array = np.array([[i*1.0/(bar_num + 1) for i in range(bar_num + 1)]] * len(float_feat))  # 分桶 \n",
    "    value_array = None\n",
    "    if method == 'gravitation':\n",
    "        value_array = 1/(np.abs(key_array - float_feat[:,None] + 0.00001))**2\n",
    "        value_array = value_array/np.sum(value_array,axis=1, keepdims=True)\n",
    "    if method == 'sofmax':\n",
    "        value_array = 1 / np.abs(key_array - float_feat[:, None] + 0.00001)\n",
    "        value_array = numpy_softmax(value_array)\n",
    "    return key_array,value_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.16666667, 0.33333333, 0.5       , 0.66666667,\n",
       "       0.83333333, 1.        ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_feat = [0,1,2,3,4,5,6]\n",
    "(float_feat-np.min(float_feat))*1.0 / np.max(float_feat-np.min(float_feat)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.04761905, 0.0952381 , 0.14285714, 0.19047619,\n",
       "        0.23809524, 0.28571429, 0.33333333, 0.38095238, 0.42857143,\n",
       "        0.47619048, 0.52380952, 0.57142857, 0.61904762, 0.66666667,\n",
       "        0.71428571, 0.76190476, 0.80952381, 0.85714286, 0.9047619 ,\n",
       "        0.95238095],\n",
       "       [0.        , 0.04761905, 0.0952381 , 0.14285714, 0.19047619,\n",
       "        0.23809524, 0.28571429, 0.33333333, 0.38095238, 0.42857143,\n",
       "        0.47619048, 0.52380952, 0.57142857, 0.61904762, 0.66666667,\n",
       "        0.71428571, 0.76190476, 0.80952381, 0.85714286, 0.9047619 ,\n",
       "        0.95238095],\n",
       "       [0.        , 0.04761905, 0.0952381 , 0.14285714, 0.19047619,\n",
       "        0.23809524, 0.28571429, 0.33333333, 0.38095238, 0.42857143,\n",
       "        0.47619048, 0.52380952, 0.57142857, 0.61904762, 0.66666667,\n",
       "        0.71428571, 0.76190476, 0.80952381, 0.85714286, 0.9047619 ,\n",
       "        0.95238095],\n",
       "       [0.        , 0.04761905, 0.0952381 , 0.14285714, 0.19047619,\n",
       "        0.23809524, 0.28571429, 0.33333333, 0.38095238, 0.42857143,\n",
       "        0.47619048, 0.52380952, 0.57142857, 0.61904762, 0.66666667,\n",
       "        0.71428571, 0.76190476, 0.80952381, 0.85714286, 0.9047619 ,\n",
       "        0.95238095],\n",
       "       [0.        , 0.04761905, 0.0952381 , 0.14285714, 0.19047619,\n",
       "        0.23809524, 0.28571429, 0.33333333, 0.38095238, 0.42857143,\n",
       "        0.47619048, 0.52380952, 0.57142857, 0.61904762, 0.66666667,\n",
       "        0.71428571, 0.76190476, 0.80952381, 0.85714286, 0.9047619 ,\n",
       "        0.95238095],\n",
       "       [0.        , 0.04761905, 0.0952381 , 0.14285714, 0.19047619,\n",
       "        0.23809524, 0.28571429, 0.33333333, 0.38095238, 0.42857143,\n",
       "        0.47619048, 0.52380952, 0.57142857, 0.61904762, 0.66666667,\n",
       "        0.71428571, 0.76190476, 0.80952381, 0.85714286, 0.9047619 ,\n",
       "        0.95238095],\n",
       "       [0.        , 0.04761905, 0.0952381 , 0.14285714, 0.19047619,\n",
       "        0.23809524, 0.28571429, 0.33333333, 0.38095238, 0.42857143,\n",
       "        0.47619048, 0.52380952, 0.57142857, 0.61904762, 0.66666667,\n",
       "        0.71428571, 0.76190476, 0.80952381, 0.85714286, 0.9047619 ,\n",
       "        0.95238095]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar_num = 20 \n",
    "np.array([[i*1.0/(bar_num + 1) for i in range(bar_num + 1)]] * len(float_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53416258, 0.01761049, 0.34322868, 0.26593143, 0.093144  ,\n",
       "       0.67566761, 0.6367115 , 0.13800769, 0.20335424, 0.45804717])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_varlen_multiply_list(embedding_dict, features, varlen_sparse_feature_columns_name_dict):\n",
    "    multiply_vec_list = []\n",
    "    print(embedding_dict)\n",
    "    for key_feature in varlen_sparse_feature_columns_name_dict:\n",
    "        for value_feature in varlen_sparse_feature_columns_name_dict[key_feature]:\n",
    "            key_feature_length_name = key_feature.name + '_seq_length'\n",
    "            if isinstance(value_feature, VarLenSparseFeat):\n",
    "                value_input = embedding_dict[value_feature.name]\n",
    "            elif isinstance(value_feature, DenseFeat):\n",
    "                value_input = features[value_feature.name]\n",
    "            else:\n",
    "                raise TypeError(\"Invalid feature column type,got\",type(value_feature))\n",
    "            if key_feature_length_name in features:\n",
    "                varlen_vec = SequenceMultiplyLayer(supports_masking=False)(\n",
    "                    [embedding_dict[key_feature.name], features[key_feature_length_name], value_input])\n",
    "                vec = SequencePoolingLayer('sum', supports_masking=False)(\n",
    "                    [varlen_vec, features[key_feature_length_name]])\n",
    "            else:\n",
    "                varlen_vec = SequenceMultiplyLayer(supports_masking=True)(\n",
    "                    [embedding_dict[key_feature.name], value_input])\n",
    "                vec = SequencePoolingLayer('sum', supports_masking=True)( varlen_vec)\n",
    "            multiply_vec_list.append(vec)\n",
    "    return multiply_vec_list\n",
    "\n",
    "class SequenceMultiplyLayer(Layer):\n",
    "    def __init__(self, supports_masking, **kwargs):\n",
    "        super(SequenceMultiplyLayer, self).__init__(**kwargs)\n",
    "        self.supports_masking = supports_masking\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if not self.supports_masking:\n",
    "            self.seq_len_max = int(input_shape[0][1])\n",
    "        super(SequenceMultiplyLayer, self).build(\n",
    "            input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, input_list, mask=None, **kwargs):\n",
    "        if self.supports_masking:\n",
    "            if mask is None:\n",
    "                raise ValueError(\n",
    "                    \"When supports_masking=True,input must support masking\")\n",
    "            key_input, value_input = input_list\n",
    "            mask = tf.cast(mask[0], tf.float32)\n",
    "            mask = tf.expand_dims(mask, axis=2)\n",
    "        else:\n",
    "            key_input, key_length_input, value_input = input_list\n",
    "            mask = tf.sequence_mask(key_length_input,   # shape为[batch_size, 1]\n",
    "                                    self.seq_len_max, dtype=tf.float32)\n",
    "            mask = tf.transpose(mask, (0, 2, 1))\n",
    "\n",
    "        embedding_size = key_input.shape[-1]\n",
    "        mask = tf.tile(mask, [1, 1, embedding_size])\n",
    "        key_input *= mask\n",
    "        if len(tf.shape(value_input)) == 2:\n",
    "            value_input = tf.expand_dims(value_input, axis=2)\n",
    "            value_input = tf.tile(value_input, [1, 1, embedding_size])\n",
    "        return tf.multiply(key_input,value_input)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]\n",
    "\n",
    "    def compute_mask(self, inputs, mask):\n",
    "        if self.supports_masking:\n",
    "            return mask[0]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_config(self, ):\n",
    "        config = {'supports_masking': self.supports_masking}\n",
    "        base_config = super(SequenceMultiplyLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x1624d9793c8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ True False False False False]]\n",
      "\n",
      " [[ True  True  True False False]]\n",
      "\n",
      " [[ True  True False False False]]]\n",
      "(3, 1, 5)\n",
      "[[[ True]\n",
      "  [False]\n",
      "  [False]\n",
      "  [False]\n",
      "  [False]]\n",
      "\n",
      " [[ True]\n",
      "  [ True]\n",
      "  [ True]\n",
      "  [False]\n",
      "  [False]]\n",
      "\n",
      " [[ True]\n",
      "  [ True]\n",
      "  [False]\n",
      "  [False]\n",
      "  [False]]] (3, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "x = tf.sequence_mask([[1], [3], [2]], 5)\n",
    "print(x.eval())\n",
    "print(x.shape)\n",
    "x = tf.transpose(x, [0, 2, 1])\n",
    "print(x.eval(), x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
